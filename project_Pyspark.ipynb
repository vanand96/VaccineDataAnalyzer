{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random \n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "# sc = pyspark.SparkContext(appName=\"myAppName\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------+----------+--------+--------------------+----------+---------------+--------------------+-----+--------------------+-----------+--------------------+------+-------------+--------------+-----------+--------+--------+--------------------+-------+---------+-----+----+----+------+----------+-------+----------+--------------------+------------+\n",
      "|                 id|    conversation_id|   created_at|      date|    time|            timezone|   user_id|       username|                name|place|               tweet|   mentions|                urls|photos|replies_count|retweets_count|likes_count|hashtags|cashtags|                link|retweet|quote_url|video|near| geo|source|user_rt_id|user_rt|retweet_id|            reply_to|retweet_date|\n",
      "+-------------------+-------------------+-------------+----------+--------+--------------------+----------+---------------+--------------------+-----+--------------------+-----------+--------------------+------+-------------+--------------+-----------+--------+--------+--------------------+-------+---------+-----+----+----+------+----------+-------+----------+--------------------+------------+\n",
      "|1179751797377748992|1179679963458392065|1570109721000|2019-10-03|16:35:21|E. Africa Standar...| 118965754|peaceahappiness|    Ein guter Freund| null|Thinks:  ... teta...|['carlzha']|                  []|    []|            0|             0|          0|      []|      []|https://twitter.c...|  False|     null|    0|null|null|  null|      null|   null|      null|[{'user_id': '118...|        null|\n",
      "|1179751771780141056|1179751771780141056|1570109715000|2019-10-03|16:35:15|E. Africa Standar...|2798966764|briannacelegill|Brianna Celeste G...| null|Forced Vaccinatio...|['youtube']|['https://youtu.b...|    []|            0|             0|          0|      []|      []|https://twitter.c...|  False|     null|    0|null|null|  null|      null|   null|      null|[{'user_id': '279...|        null|\n",
      "+-------------------+-------------------+-------------+----------+--------+--------------------+----------+---------------+--------------------+-----+--------------------+-----------+--------------------+------+-------------+--------------+-----------+--------+--------+--------------------+-------+---------+-----+----+----+------+----------+-------+----------+--------------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleFile = \"C:/Users/avadavelli/Downloads/twitter-vaccination-dataset/vaccination2.csv\"\n",
    "reader = spark.read \n",
    "reader.option(\"header\",True)\n",
    "reader.option(\"inferSchema\",True)\n",
    "df = reader.csv(peopleFile)\n",
    "df.show(2)\n",
    "# df.head()\n",
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: ['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone', 'user_id', 'username', 'name', 'place', 'tweet', 'mentions', 'urls', 'photos', 'replies_count', 'retweets_count', 'likes_count', 'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video', 'near', 'geo', 'source', 'user_rt_id', 'user_rt', 'retweet_id', 'reply_to', 'retweet_date']\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- conversation_id: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- timezone: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- place: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- mentions: string (nullable = true)\n",
      " |-- urls: string (nullable = true)\n",
      " |-- photos: string (nullable = true)\n",
      " |-- replies_count: string (nullable = true)\n",
      " |-- retweets_count: string (nullable = true)\n",
      " |-- likes_count: string (nullable = true)\n",
      " |-- hashtags: string (nullable = true)\n",
      " |-- cashtags: string (nullable = true)\n",
      " |-- link: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- quote_url: string (nullable = true)\n",
      " |-- video: string (nullable = true)\n",
      " |-- near: string (nullable = true)\n",
      " |-- geo: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user_rt_id: string (nullable = true)\n",
      " |-- user_rt: string (nullable = true)\n",
      " |-- retweet_id: string (nullable = true)\n",
      " |-- reply_to: string (nullable = true)\n",
      " |-- retweet_date: string (nullable = true)\n",
      "\n",
      "Schema:  None\n"
     ]
    }
   ],
   "source": [
    "# print('Dataset size:',df.describe())\n",
    "print('Columns are:',df.columns)\n",
    "print('Schema: ', df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: date, tweet: string, hashtags: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "df = df.select(df['date'].cast(DateType()), \"tweet\", \"hashtags\") \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|      date|               tweet|            hashtags|\n",
      "+----------+--------------------+--------------------+\n",
      "|2019-10-03|Thinks:  ... teta...|                  []|\n",
      "|2019-10-03|Forced Vaccinatio...|                  []|\n",
      "|2019-10-03|We have had our f...|                  []|\n",
      "|2019-10-03|That's true, they...|                  []|\n",
      "|2019-10-03|Flu vaccination d...|         ['#fluvax']|\n",
      "|2019-10-03|What did farmers ...|['#tbfree', '#bad...|\n",
      "|2019-10-03|An employee at Tu...|                  []|\n",
      "|2019-10-03|#Nigeria: An outb...|        ['#nigeria']|\n",
      "|2019-10-03|Impressive number...|['#vaccination', ...|\n",
      "|2019-10-03|‚Å¶@DrBGellin‚Å© @Sab...|['#research', '#v...|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\avadavelli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\avadavelli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "MIN_YEAR = 1900\n",
    "MAX_YEAR = 2100\n",
    "\n",
    "\n",
    "def get_url_patern():\n",
    "    return re.compile(\n",
    "        r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))'\n",
    "        r'[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})')\n",
    "\n",
    "\n",
    "def get_emojis_pattern():\n",
    "    try:\n",
    "        # UCS-4\n",
    "        emojis_pattern = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
    "    except re.error:\n",
    "        # UCS-2\n",
    "        emojis_pattern = re.compile(\n",
    "            u'([\\u2600-\\u27BF])|([\\uD83C][\\uDF00-\\uDFFF])|([\\uD83D][\\uDC00-\\uDE4F])|([\\uD83D][\\uDE80-\\uDEFF])')\n",
    "    return emojis_pattern\n",
    "\n",
    "\n",
    "def get_hashtags_pattern():\n",
    "    return re.compile(r'#\\w*')\n",
    "\n",
    "\n",
    "def get_single_letter_words_pattern():\n",
    "    return re.compile(r'(?<![\\w\\-])\\w(?![\\w\\-])')\n",
    "\n",
    "\n",
    "def get_blank_spaces_pattern():\n",
    "    return re.compile(r'\\s{2,}|\\t')\n",
    "\n",
    "\n",
    "def get_twitter_reserved_words_pattern():\n",
    "    return re.compile(r'(RT|rt|FAV|fav|VIA|via)')\n",
    "\n",
    "\n",
    "def get_mentions_pattern():\n",
    "    return re.compile(r'@\\w*')\n",
    "\n",
    "\n",
    "def is_year(text):\n",
    "    if (len(text) == 3 or len(text) == 4) and (MIN_YEAR < len(text) < MAX_YEAR):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "class TwitterPreprocessor:\n",
    "\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "\n",
    "    def fully_preprocess(self):\n",
    "        return self \\\n",
    "            .remove_urls() \\\n",
    "            .remove_mentions() \\\n",
    "            .remove_hashtags() \\\n",
    "            .remove_twitter_reserved_words() \\\n",
    "            .remove_punctuation() \\\n",
    "            .remove_single_letter_words() \\\n",
    "            .remove_blank_spaces() \\\n",
    "            .remove_stopwords() \\\n",
    "            .remove_numbers()\n",
    "\n",
    "    def remove_urls(self):\n",
    "        self.text = re.sub(pattern=get_url_patern(), repl='', string=self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        self.text = self.text.translate(str.maketrans('', '', string.punctuation))\n",
    "        return self\n",
    "\n",
    "    def remove_mentions(self):\n",
    "        self.text = re.sub(pattern=get_mentions_pattern(), repl='', string=self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_hashtags(self):\n",
    "        self.text = re.sub(pattern=get_hashtags_pattern(), repl='', string=self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_twitter_reserved_words(self):\n",
    "        self.text = re.sub(pattern=get_twitter_reserved_words_pattern(), repl='', string=self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_single_letter_words(self):\n",
    "        self.text = re.sub(pattern=get_single_letter_words_pattern(), repl='', string=self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_blank_spaces(self):\n",
    "        self.text = re.sub(pattern=get_blank_spaces_pattern(), repl=' ', string=self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_stopwords(self, extra_stopwords=None):\n",
    "        if extra_stopwords is None:\n",
    "            extra_stopwords = []\n",
    "        text = nltk.word_tokenize(self.text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        new_sentence = []\n",
    "        for w in text:\n",
    "            if w not in stop_words and w not in extra_stopwords:\n",
    "                new_sentence.append(w)\n",
    "        self.text = ' '.join(new_sentence)\n",
    "        return self\n",
    "\n",
    "    def remove_numbers(self, preserve_years=False):\n",
    "        text_list = self.text.split(' ')\n",
    "        for text in text_list:\n",
    "            if text.isnumeric():\n",
    "                if preserve_years:\n",
    "                    if not is_year(text):\n",
    "                        text_list.remove(text)\n",
    "                else:\n",
    "                    text_list.remove(text)\n",
    "\n",
    "        self.text = ' '.join(text_list)\n",
    "        return self\n",
    "\n",
    "    def lowercase(self):\n",
    "        self.text = self.text.lower()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_array = [str(row.tweet) for row in df.collect()]\n",
    "# tweets_array\n",
    "# Clean tweets and append to new column\n",
    "tweets = [str(row.tweet) for row in df.collect()]\n",
    "clean_tweets = []\n",
    "for tweet in tweets:\n",
    "    c = TwitterPreprocessor((tweet))\n",
    "    c.fully_preprocess()\n",
    "    c = c.text\n",
    "    clean_tweets.append(c)\n",
    "    \n",
    "# df['clean_tweets'] = clean_tweets \n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(clean_tweets='Thinks tetanus vaccination currently üòâ'),\n",
       " Row(clean_tweets='Forced Vaccination Its Ties To Eugenics David Icke'),\n",
       " Row(clean_tweets='We flu vaccination protect patients staff families ‚Ä¶'),\n",
       " Row(clean_tweets='Thats true known contraindications vaccination Docs know stuff'),\n",
       " Row(clean_tweets='Flu vaccination pregnancy safe helps protect mothers flu pregnancy helps protect babies several months bih This impoant since babies months ‚Äô get'),\n",
       " Row(clean_tweets='What farmers make Badger Vaccination Deployment Project views changed time Our longitudinal analysis ‚Ä¶ ¬£¬£ free ‚Ä¶'),\n",
       " Row(clean_tweets='An employee Turning Stone Reso Casino Oneida County diagnosed infectious hepatitis last week forcing hurried vaccination guests workers pictwittercomhTCAB8muoj'),\n",
       " Row(clean_tweets='An outbreak yellow fever ongoing Proof vaccination required enter country If travel area consult health care professional least weeks trip protect insect bites httpowlyHCzl50wAr9b'),\n",
       " Row(clean_tweets='Impressive numbers So pleased continue suppoing teams skills brilliant result guys already Keeping protected üëçüíâ ‚Ä¶'),\n",
       " Row(clean_tweets='\\u2066\\u2069 urging interface \\u2066\\u2069 Joint Action Vaccination Summit pictwittercomH6RHC8jJlU')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# clean_tweets = ([\"foo\"] * df.count())\n",
    "\n",
    "pandas_df = pd.DataFrame(clean_tweets, columns={'clean_tweets'})\n",
    "df_spark = spark.createDataFrame(pandas_df)\n",
    "# df_spark.count()\n",
    "df_spark.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+\n",
      "|        clean_tweets|      date|               tweet|            hashtags|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "|On Fri PM Swindon...|2019-10-03|On Fri at 2 PM: S...|                  []|\n",
      "|If member SHSU co...|2019-10-03|If you are a memb...|                  []|\n",
      "|The move give tee...|2019-10-03|\"\"\"The move to gi...|                   0|\n",
      "|cases decision ba...|2019-10-02|#Didyouknow, in m...|['#didyouknow', '...|\n",
      "|Thats helpful sin...|2019-10-01|That's it helpful...|                  []|\n",
      "|Get involved Wear...|2019-10-01|Get involved this...|['#hpvpreventionw...|\n",
      "|Vaccine Death Sto...|2019-10-01|Vaccine Death Sto...|                  []|\n",
      "|Doctrine Original...|2019-10-01|Doctrine of Origi...|['#antigenic', '#...|\n",
      "|Could someone tel...|2019-10-01|Could someone tel...|    ['#vaccination']|\n",
      "|Great Many health...|2019-10-01|\"Great! Many heal...|                   1|\n",
      "|annual flu vaccin...|2019-10-01|@Ral_sez @NHSBart...|['#fluboxfestival...|\n",
      "|Vaccination singl...|2019-10-01|Vaccination with ...|['#biorxiv_micrbio']|\n",
      "|Research ‚Äô heal s...|2019-10-01|Research won‚Äôt he...|                  []|\n",
      "|What ‚Äô flu shot D...|2019-10-01|What‚Äôs a flu shot...|                  []|\n",
      "|An impoant read v...|2019-09-30|An important read...|    ['#kennelcough']|\n",
      "|‚Äô sure tbh compul...|2019-09-30|I‚Äôm not sure tbh....|                  []|\n",
      "|Should vaccinatio...|2019-09-30|Should the vaccin...|                  []|\n",
      "|Vaccination neces...|2019-09-30|#SwasthImmunisedI...|['#swasthimmunise...|\n",
      "|go vet vaccinatio...|2019-09-29|we go to the vet ...|                  []|\n",
      "|Percent Children ...|2019-09-29|54 Percent of Chi...|                  []|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "df = df.withColumn(\"id\", monotonically_increasing_id())\n",
    "df_spark = df_spark.withColumn(\"id\", monotonically_increasing_id())\n",
    "# df_spark.show()\n",
    "df3 = df_spark.join(df, \"id\", \"outer\").drop(\"id\")\n",
    "df3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
